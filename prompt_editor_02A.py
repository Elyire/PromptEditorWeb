# from dotenv import load_dotenv
# from pathlib import Path
import os
import base64
import io

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ë¶€ë¶„ ì œê±° (ì›¹ ë°°í¬ë¥¼ ìœ„í•´)
# ì´ì œ ì‚¬ìš©ìê°€ ì§ì ‘ API í‚¤ë¥¼ ì…ë ¥í•˜ê²Œ ë©ë‹ˆë‹¤

import streamlit as st
import json
import hashlib
import datetime
import re
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser



# í˜ì´ì§€ êµ¬ì„± ì„¤ì •.
st.set_page_config(layout="wide", page_title="Prompt Editor")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
def init_session_state():
    if "system_prompt" not in st.session_state:
        st.session_state.system_prompt = ""
    if "user_prompt" not in st.session_state:
        st.session_state.user_prompt = ""
    if "response" not in st.session_state:
        st.session_state.response = ""
    if "current_version" not in st.session_state:
        st.session_state.current_version = 0
    if "versions" not in st.session_state:
        st.session_state.versions = []
    if "prompt_name" not in st.session_state:
        st.session_state.prompt_name = "Untitled Prompt"
    if "saved_prompts" not in st.session_state:
        st.session_state.saved_prompts = {}
    if "show_history" not in st.session_state:
        st.session_state.show_history = False
    if "current_prompt_id" not in st.session_state:
        st.session_state.current_prompt_id = None
    if "variables" not in st.session_state:
        st.session_state.variables = {}
    if "template_user_prompt" not in st.session_state:
        st.session_state.template_user_prompt = ""
    if "show_variables" not in st.session_state:
        st.session_state.show_variables = False
    if "model_name" not in st.session_state:
        st.session_state.model_name = "gemini-2.0-flash"
    if "temperature" not in st.session_state:
        st.session_state.temperature = 0.5
    if "max_tokens" not in st.session_state:
        st.session_state.max_tokens = 4000
    # API í‚¤ ê´€ë ¨ ìƒíƒœ ì¶”ê°€
    if "openai_api_key" not in st.session_state:
        st.session_state.openai_api_key = ""
    if "anthropic_api_key" not in st.session_state:
        st.session_state.anthropic_api_key = ""
    if "gemini_api_key" not in st.session_state:
        st.session_state.gemini_api_key = ""
    # ì„ íƒëœ ëª¨ë¸ ì œê³µì—…ì²´
    if "selected_provider" not in st.session_state:
        st.session_state.selected_provider = None
    # ì•± ìƒíƒœ (ì„¤ì • or ì‚¬ìš© ëª¨ë“œ)
    if "app_mode" not in st.session_state:
        st.session_state.app_mode = "setup"  # ì´ˆê¸°ê°’ì€ "setup", í‚¤ ì„¤ì • í›„ "editor"ë¡œ ë³€ê²½

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” í•¨ìˆ˜ í˜¸ì¶œ
init_session_state()

# í”„ë¡¬í”„íŠ¸ í•´ì‹œ ìƒì„± í•¨ìˆ˜
def generate_hash(system_prompt, user_prompt):
    # template_user_promptë¥¼ ì‚¬ìš©í•˜ì—¬ í•´ì‹œ ìƒì„± (ì‹¤ì œ ë³€ìˆ˜ ê°’ì´ ì ìš©ëœ user_prompt ëŒ€ì‹ )
    # ì´ë ‡ê²Œ í•˜ë©´ ë³€ìˆ˜ ê°’ë§Œ ë°”ë€Œì—ˆì„ ë•ŒëŠ” í•´ì‹œê°€ ë³€ê²½ë˜ì§€ ì•ŠìŒ
    combined = system_prompt + st.session_state.template_user_prompt
    return hashlib.md5(combined.encode()).hexdigest()

# ë²„ì „ ì €ì¥ í•¨ìˆ˜
def save_version(system_prompt, user_prompt, template_user_prompt=None):
    if template_user_prompt is None:
        template_user_prompt = st.session_state.template_user_prompt or user_prompt
        
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ í…œí”Œë¦¿ ìœ ì € í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•´ì‹œ ìƒì„±
    # ë³€ìˆ˜ ê°’ì´ ì ìš©ëœ user_promptëŠ” í•´ì‹œ ìƒì„±ì— ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
    current_hash = generate_hash(system_prompt, template_user_prompt)
    
    # ìƒˆ ë²„ì „ì¸ì§€ í™•ì¸ (í•´ì‹œê°€ ë‹¤ë¥¸ ê²½ìš°)
    if not st.session_state.versions or current_hash != st.session_state.versions[-1]["hash"]:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        new_version = {
            "version": len(st.session_state.versions) + 1,
            "timestamp": timestamp,
            "system_prompt": system_prompt,
            "user_prompt": user_prompt,
            "template_user_prompt": template_user_prompt,
            "hash": current_hash
        }
        st.session_state.versions.append(new_version)
        st.session_state.current_version = len(st.session_state.versions)
        return True
    return False

# ë²„ì „ ë¡œë“œ í•¨ìˆ˜
def load_version(version_index):
    if 0 <= version_index < len(st.session_state.versions):
        version = st.session_state.versions[version_index]
        st.session_state.system_prompt = version["system_prompt"]
        st.session_state.user_prompt = version["user_prompt"]
        
        # ë²„ì „ì— í…œí”Œë¦¿ì´ ìˆìœ¼ë©´ ë¡œë“œ
        if "template_user_prompt" in version:
            st.session_state.template_user_prompt = version["template_user_prompt"]
        else:
            # í…œí”Œë¦¿ì´ ì—†ìœ¼ë©´ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ í…œí”Œë¦¿ìœ¼ë¡œ ì‚¬ìš©
            st.session_state.template_user_prompt = version["user_prompt"]
        
        st.session_state.current_version = version_index + 1
        return True
    return False

# í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì €ì¥ í•¨ìˆ˜
def save_prompt_to_file():
    if not os.path.exists("prompts"):
        os.makedirs("prompts")
    
    # í”„ë¡¬í”„íŠ¸ì— ê³ ìœ  IDê°€ ì—†ìœ¼ë©´ ìƒì„±
    if not st.session_state.current_prompt_id:
        st.session_state.current_prompt_id = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
    
    prompt_data = {
        "name": st.session_state.prompt_name,
        "versions": st.session_state.versions,
        "current_version": st.session_state.current_version,
        "prompt_id": st.session_state.current_prompt_id,
        "template_user_prompt": st.session_state.template_user_prompt,
        "variables": st.session_state.variables,
        "system_prompt": st.session_state.system_prompt
    }
    
    # íŒŒì¼ëª…ì— í”„ë¡¬í”„íŠ¸ IDë¥¼ í¬í•¨í•˜ì—¬ ê³ ìœ ì„± ë³´ì¥
    filename = f"prompts/{st.session_state.current_prompt_id}_{st.session_state.prompt_name.replace(' ', '_')}.json"
    with open(filename, "w") as f:
        json.dump(prompt_data, f, indent=2)


    # # íŒŒì¼ëª…ì— í”„ë¡¬í”„íŠ¸ IDë¥¼ í¬í•¨í•˜ì—¬ ê³ ìœ ì„± ë³´ì¥
    # filename = f"prompts/{st.session_state.current_prompt_id}_{st.session_state.prompt_name.replace(' ', '_')}.json"
    # with open(filename, "w", encoding="utf-8") as f:
    #     json.dump(prompt_data, f, indent=2, ensure_ascii=False)

    
    # ì €ì¥ëœ í”„ë¡¬í”„íŠ¸ ëª©ë¡ ì—…ë°ì´íŠ¸
    st.session_state.saved_prompts[st.session_state.prompt_name] = filename
    return filename

# í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ í•¨ìˆ˜
def load_prompt_from_file(prompt_name):
    filename = st.session_state.saved_prompts.get(prompt_name)
    if filename and os.path.exists(filename):
        with open(filename, "r") as f:
            prompt_data = json.load(f)
        
        # ë¡œë“œí•˜ê¸° ì „ì— í˜„ì¬ ë²„ì „ ê¸°ë¡ ì´ˆê¸°í™”
        st.session_state.versions = []
        
        st.session_state.prompt_name = prompt_data["name"]
        st.session_state.versions = prompt_data["versions"]
        st.session_state.current_version = prompt_data["current_version"]
        
        # í˜„ì¬ í”„ë¡¬í”„íŠ¸ ID ì„¤ì •
        if "prompt_id" in prompt_data:
            st.session_state.current_prompt_id = prompt_data["prompt_id"]
        else:
            # ì´ì „ì— ì €ì¥ëœ í”„ë¡¬í”„íŠ¸ìš© ID ìƒì„±
            st.session_state.current_prompt_id = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
        
        # í…œí”Œë¦¿ê³¼ ë³€ìˆ˜ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
        if "template_user_prompt" in prompt_data:
            st.session_state.template_user_prompt = prompt_data["template_user_prompt"]
        else:
            st.session_state.template_user_prompt = ""
            
        # ë³€ìˆ˜ ì´ˆê¸°í™” (ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì„¤ì •)
        # ì €ì¥ëœ ë³€ìˆ˜ ê°’ì„ ë¡œë“œí•˜ì§€ ì•Šê³  ë¹ˆ ê°’ìœ¼ë¡œ ì‹œì‘
        st.session_state.variables = {}
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
        if "system_prompt" in prompt_data:
            st.session_state.system_prompt = prompt_data["system_prompt"]
        else:
            st.session_state.system_prompt = ""
        
        # í˜„ì¬ ë²„ì „ ë¡œë“œ
        current_idx = st.session_state.current_version - 1
        if 0 <= current_idx < len(st.session_state.versions):
            version = st.session_state.versions[current_idx]
            st.session_state.system_prompt = version["system_prompt"]
            st.session_state.user_prompt = version["user_prompt"]
        
        return True
    return False

# ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ê²€ìƒ‰ í•¨ìˆ˜
def scan_for_prompts():
    if not os.path.exists("prompts"):
        os.makedirs("prompts")
    
    saved_prompts = {}
    for filename in os.listdir("prompts"):
        if filename.endswith(".json"):
            try:
                with open(os.path.join("prompts", filename), "r") as f:
                    prompt_data = json.load(f)
                prompt_name = prompt_data.get("name", filename[:-5].replace("_", " "))
                saved_prompts[prompt_name] = os.path.join("prompts", filename)
            except:
                pass
    
    st.session_state.saved_prompts = saved_prompts
    
    # ìƒˆ ì„¸ì…˜ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ID ìƒì„±
    if st.session_state.current_prompt_id is None:
        st.session_state.current_prompt_id = datetime.datetime.now().strftime("%Y%m%d%H%M%S")

# ì‹œì‘ ì‹œ ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ê²€ìƒ‰
if not st.session_state.saved_prompts:
    scan_for_prompts()

# í”„ë¡¬í”„íŠ¸ì—ì„œ ë³€ìˆ˜ ì¶”ì¶œ í•¨ìˆ˜
def extract_variables(prompt):
    variables = []
    
    # {variable} ë° {{variable}} íŒ¨í„´ ëª¨ë‘ ë§¤ì¹­
    patterns = [r'\{([^{}]+)\}', r'\{\{([^{}]+)\}\}']
    
    for pattern in patterns:
        matches = re.findall(pattern, prompt)
        variables.extend(matches)
    
    # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ìˆœì„œ ìœ ì§€
    unique_vars = []
    for var in variables:
        if var not in unique_vars:
            unique_vars.append(var)
    
    return unique_vars

# í…œí”Œë¦¿ì— ë³€ìˆ˜ ì ìš© í•¨ìˆ˜
def apply_variables(template, variables_dict):
    result = template
    for var_name, var_value in variables_dict.items():
        # {var} ë° {{var}} íŒ¨í„´ ëª¨ë‘ ëŒ€ì²´
        result = result.replace('{{' + var_name + '}}', var_value)
        result = result.replace('{' + var_name + '}', var_value)
    return result

# LLM ì²´ì¸ ì´ˆê¸°í™” í•¨ìˆ˜
def get_llm_chain(model_name, temperature, max_tokens):
    if model_name.startswith("gpt"):
        llm = ChatOpenAI(
            api_key=st.session_state.openai_api_key,
            model_name=model_name,
            temperature=temperature,
            max_tokens=max_tokens,
            streaming=True
        )
    elif model_name.startswith("claude"):
        llm = ChatAnthropic(
            api_key=st.session_state.anthropic_api_key,
            model_name=model_name,
            temperature=temperature,
            max_tokens=max_tokens,
            streaming=True
        )
    elif model_name.startswith("gemini"):
        llm = ChatGoogleGenerativeAI(          
            google_api_key=st.session_state.gemini_api_key,
            model=model_name,
            temperature=temperature,
            max_tokens=max_tokens,
            # streaming=True
        )
    else:
        raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸: {model_name}")
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", "{system}"),
        ("human", "{human}")
    ])
    
    chain = prompt | llm | StrOutputParser()
    return chain

# ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_response(system_prompt, user_prompt, model_name, temperature, max_tokens):
    try:
        # API í‚¤ í™•ì¸
        if model_name.startswith("gpt") and not st.session_state.openai_api_key:
            st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            return
        elif model_name.startswith("claude") and not st.session_state.anthropic_api_key:
            st.error("Anthropic API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            return
        elif model_name.startswith("gemini") and not st.session_state.gemini_api_key:
            st.error("Google Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            return
            
        chain = get_llm_chain(model_name, temperature, max_tokens)
        
        # ì‘ë‹µ ì´ˆê¸°í™”
        st.session_state.response = ""
        
        # ê¸€ë¡œë²Œ ë³€ìˆ˜ë¡œ ì‘ë‹µ í”Œë ˆì´ìŠ¤í™€ë” ì ‘ê·¼
        global response_placeholder
        
        # ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
        for chunk in chain.stream({"system": system_prompt, "human": user_prompt}):
            st.session_state.response += chunk
            # ì‘ë‹µ í‘œì‹œ
            if 'response_placeholder' in globals():
                response_placeholder.markdown(st.session_state.response)
    except Exception as e:
        st.error(f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}")

# ì•± ì œëª©
st.title("Prompt Editor")
st.markdown("Â© 2025 cogdex | cogPromptâ„¢")

# ì•± ëª¨ë“œì— ë”°ë¼ ë‹¤ë¥¸ í™”ë©´ í‘œì‹œ (setup ë˜ëŠ” editor)
if st.session_state.app_mode == "setup":
    st.header("API í‚¤ ì„¤ì •")
    st.markdown("í”„ë¡¬í”„íŠ¸ ì—ë””í„°ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì•„ë˜ì—ì„œ ì‚¬ìš©í•  AI ëª¨ë¸ ì œê³µì—…ì²´ë¥¼ ì„ íƒí•˜ê³  í•´ë‹¹ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    # ëª¨ë¸ ì œê³µì—…ì²´ ì„ íƒ
    provider_options = ["OpenAI", "Anthropic", "Google Gemini"]
    selected_provider = st.selectbox(
        "ëª¨ë¸ ì œê³µì—…ì²´ ì„ íƒ",
        options=provider_options,
        index=provider_options.index(st.session_state.selected_provider) if st.session_state.selected_provider in provider_options else 0
    )
    st.session_state.selected_provider = selected_provider
    
    # ì„ íƒëœ ì œê³µì—…ì²´ì— ë”°ë¼ API í‚¤ ì…ë ¥ í•„ë“œ í‘œì‹œ
    api_key = ""
    if selected_provider == "OpenAI":
        api_key = st.text_input("OpenAI API Key", value=st.session_state.openai_api_key, type="password")
        st.session_state.openai_api_key = api_key
    elif selected_provider == "Anthropic":
        api_key = st.text_input("Anthropic API Key", value=st.session_state.anthropic_api_key, type="password")
        st.session_state.anthropic_api_key = api_key
    elif selected_provider == "Google Gemini":
        api_key = st.text_input("Google Gemini API Key", value=st.session_state.gemini_api_key, type="password")
        st.session_state.gemini_api_key = api_key
    
    # ì‹œì‘ ë²„íŠ¼
    if st.button("ì‹œì‘í•˜ê¸°", key="start_button"):
        if api_key:
            # ëª¨ë¸ ì„ íƒ ê¸°ë³¸ê°’ ì„¤ì •
            if selected_provider == "OpenAI":
                st.session_state.model_name = "gpt-3.5-turbo"
            elif selected_provider == "Anthropic":
                st.session_state.model_name = "claude-3-5-sonnet-20241022"
            elif selected_provider == "Google Gemini":
                st.session_state.model_name = "gemini-2.0-flash"
            
            st.session_state.app_mode = "editor"
            st.rerun()
        else:
            st.error("API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
else:
    # ê¸°ì¡´ ì—ë””í„° UI ìœ ì§€
    # ì‚¬ì´ë“œë°”ì— í”„ë¡¬í”„íŠ¸ ê´€ë¦¬, ëª¨ë¸ ì„¤ì • ë“±ì„ ë°°ì¹˜
    with st.sidebar:
        # API í‚¤ ë³€ê²½ ë²„íŠ¼ ì¶”ê°€
        if st.button("API í‚¤ ë³€ê²½", key="change_api_key"):
            st.session_state.app_mode = "setup"
            st.rerun()
            
        st.header("Prompt Management")
        
        # í”„ë¡¬í”„íŠ¸ ì´ë¦„ ë° ì €ì¥ ê¸°ëŠ¥ (ê°™ì€ í–‰ì— ë°°ì¹˜)
        name_col, save_col = st.columns([3, 1])
        with name_col:
            new_prompt_name = st.text_input("Enter Prompt Name", value=st.session_state.prompt_name, key="prompt_name_input")
            if new_prompt_name != st.session_state.prompt_name:
                st.session_state.prompt_name = new_prompt_name
                # ì™„ì „íˆ ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œ ë²„ì „ ê¸°ë¡ ì´ˆê¸°í™”
                if not any(name.lower() == new_prompt_name.lower() for name in st.session_state.saved_prompts.keys()):
                    st.session_state.versions = []
                    st.session_state.current_version = 0
        
        with save_col:
            st.write("") # ë ˆì´ë¸”ê³¼ ë²„íŠ¼ ë†’ì´ë¥¼ ë§ì¶”ê¸° ìœ„í•œ ê³µë°±
            st.write("")
            save_button_clicked = st.button("Save", key="save_button")
        
        if save_button_clicked:
            filename = save_prompt_to_file()
            st.success(f"Saved as {filename}")
        
        # ë¶ˆëŸ¬ì˜¤ê¸° ì˜µì…˜ê³¼ ë¡œë“œ ë²„íŠ¼ (ê°™ì€ í–‰ì— ë°°ì¹˜)
        prompt_options = list(st.session_state.saved_prompts.keys())
        if prompt_options:
            load_col, load_button_col = st.columns([3, 1])
            with load_col:
                selected_prompt = st.selectbox("Load Prompt", options=prompt_options, key="load_select")
            with load_button_col:
                st.write("") # ë ˆì´ë¸”ê³¼ ë²„íŠ¼ ë†’ì´ë¥¼ ë§ì¶”ê¸° ìœ„í•œ ê³µë°±
                st.write("")
                load_button_clicked = st.button("Load", key="load_button")

            # ë²„íŠ¼ í´ë¦­ ì²˜ë¦¬ë¥¼ ì»¬ëŸ¼ ë°”ê¹¥ì—ì„œ ìˆ˜í–‰
            if load_button_clicked:
                if load_prompt_from_file(selected_prompt):
                    st.success(f"Loaded: {selected_prompt}")
                else:
                    st.error("Failed to load prompt")

        # ë‹¤ìš´ë¡œë“œ/ì—…ë¡œë“œ ê¸°ëŠ¥ ì¶”ê°€
        st.write("---")
        st.subheader("Import/Export Prompt")
        
        # ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥
        if st.button("ğŸ“¥ Download Current Prompt"):
            # í˜„ì¬ í”„ë¡¬í”„íŠ¸ ë°ì´í„° ìƒì„±
            prompt_data = {
                "name": st.session_state.prompt_name,
                "versions": st.session_state.versions,
                "current_version": st.session_state.current_version,
                "prompt_id": st.session_state.current_prompt_id or datetime.datetime.now().strftime("%Y%m%d%H%M%S"),
                "template_user_prompt": st.session_state.template_user_prompt,
                "variables": {},  # ë³€ìˆ˜ ê°’ì€ ì €ì¥í•˜ì§€ ì•ŠìŒ
                "system_prompt": st.session_state.system_prompt
            }
            
            # JSON íŒŒì¼ë¡œ ë³€í™˜
            json_str = json.dumps(prompt_data, indent=2)
            b64 = base64.b64encode(json_str.encode()).decode()
            
            # ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„±
            filename = f"{st.session_state.prompt_name.replace(' ', '_')}.json"
            href = f'<a href="data:file/json;base64,{b64}" download="{filename}">Click to download {filename}</a>'
            st.markdown(href, unsafe_allow_html=True)
        
        # ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜
        def process_uploaded_file():
            if "uploaded_file" in st.session_state and st.session_state.uploaded_file is not None:
                try:
                    # ì—…ë¡œë“œëœ íŒŒì¼ ë‚´ìš© ì½ê¸°
                    content = st.session_state.uploaded_file.read()
                    prompt_data = json.loads(content.decode())
                    
                    # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                    st.session_state.prompt_name = prompt_data["name"]
                    st.session_state.versions = prompt_data["versions"]
                    st.session_state.current_version = prompt_data["current_version"]
                    
                    # í”„ë¡¬í”„íŠ¸ ID ì„¤ì •
                    if "prompt_id" in prompt_data:
                        st.session_state.current_prompt_id = prompt_data["prompt_id"]
                    else:
                        # ì´ì „ì— ì €ì¥ëœ í”„ë¡¬í”„íŠ¸ìš© ID ìƒì„±
                        st.session_state.current_prompt_id = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
                    
                    # í…œí”Œë¦¿ ë¡œë“œ
                    if "template_user_prompt" in prompt_data:
                        st.session_state.template_user_prompt = prompt_data["template_user_prompt"]
                    else:
                        st.session_state.template_user_prompt = ""
                    
                    # ë³€ìˆ˜ëŠ” í•­ìƒ ë¹ˆ ìƒíƒœë¡œ ì´ˆê¸°í™”
                    st.session_state.variables = {}
                    
                    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
                    if "system_prompt" in prompt_data:
                        st.session_state.system_prompt = prompt_data["system_prompt"]
                    else:
                        st.session_state.system_prompt = ""
                    
                    # í˜„ì¬ ë²„ì „ ë¡œë“œ
                    current_idx = st.session_state.current_version - 1
                    if st.session_state.versions and 0 <= current_idx < len(st.session_state.versions):
                        version = st.session_state.versions[current_idx]
                        st.session_state.system_prompt = version["system_prompt"]
                        st.session_state.user_prompt = version["user_prompt"]
                        if "template_user_prompt" in version:
                            st.session_state.template_user_prompt = version["template_user_prompt"]
                    
                    st.success(f"Prompt '{st.session_state.prompt_name}' successfully uploaded!")
                    
                    # íŒŒì¼ ì—…ë¡œë” ìƒíƒœ ì´ˆê¸°í™”
                    st.session_state.uploaded_file = None
                    
                except Exception as e:
                    st.error(f"Error uploading prompt file: {str(e)}")
        
        # íŒŒì¼ì´ ì—…ë¡œë“œë˜ë©´ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        def on_file_upload():
            st.session_state.uploaded_file = uploaded_file
        
        # ì—…ë¡œë“œ ê¸°ëŠ¥
        uploaded_file = st.file_uploader("ğŸ“¤ Upload Prompt File", type=["json"], on_change=on_file_upload)
        
        # ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬
        process_uploaded_file()

        # ìƒˆ í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ”„ :gray[**Create New Prompt**]", key="new_prompt_button"):
            # ìƒˆë¡œê³ ì¹¨ê³¼ ë¹„ìŠ·í•˜ê²Œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.system_prompt = ""
            st.session_state.user_prompt = ""
            st.session_state.response = ""
            st.session_state.current_version = 0
            st.session_state.versions = []
            st.session_state.prompt_name = "Untitled Prompt"
            st.session_state.current_prompt_id = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
            st.session_state.variables = {}
            st.session_state.template_user_prompt = ""
            st.session_state.show_variables = False
            # ìƒˆë¡œê³ ì¹¨ íš¨ê³¼ë¥¼ ìœ„í•´ ë¦¬ë¡œë“œ
            st.rerun()
        
        st.write("---")

        # ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •
        st.header("Model Parameters")
        
        # ì„ íƒëœ ì œê³µì—…ì²´ì— ë”°ë¼ ëª¨ë¸ ì˜µì…˜ í•„í„°ë§
        if st.session_state.selected_provider == "OpenAI":
            model_options = [
                "gpt-4o",
                "gpt-4o-mini",
                "gpt-3.5-turbo",
            ]
        elif st.session_state.selected_provider == "Anthropic":
            model_options = [
                "claude-3-7-sonnet-20250219",
                "claude-3-5-sonnet-20241022",
                "claude-3-5-sonnet-20240620",
                "claude-3-5-haiku-20241022",
                "claude-3-haiku-20240307",
            ]
        elif st.session_state.selected_provider == "Google Gemini":
            model_options = [
                "gemini-2.0-flash",
                "gemini-2.5-pro-exp-03-25",
            ]
        else:
            # ê¸°ë³¸ ì˜µì…˜
            model_options = [
                "gemini-2.0-flash",
                "claude-3-5-sonnet-20241022",
                "gpt-3.5-turbo",
            ]
            
        # í˜„ì¬ ì„ íƒëœ ëª¨ë¸ì´ ì˜µì…˜ì— ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ëª¨ë¸ ì„ íƒ
        default_index = 0
        if st.session_state.model_name in model_options:
            default_index = model_options.index(st.session_state.model_name)
            
        selected_model = st.selectbox(
            "Select Model", 
            options=model_options, 
            index=default_index, 
            key="model_select"
        )
        st.session_state.model_name = selected_model
        
        selected_temp = st.slider("Temperature", min_value=0.0, max_value=1.0, value=st.session_state.temperature, step=0.1, key="temp_slider")
        st.session_state.temperature = selected_temp
        
        selected_tokens = st.number_input("Max Tokens", min_value=1, max_value=4096, value=st.session_state.max_tokens, step=100, key="tokens_input")
        st.session_state.max_tokens = selected_tokens
        
        # ì‘ë‹µ í‘œì‹œë¥¼ ìœ„í•œ ì „ì—­ í”Œë ˆì´ìŠ¤í™€ë” ì„ ì–¸
        global response_placeholder
        
        st.write("---")
        
        # ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ (ì ‘ì„ ìˆ˜ ìˆëŠ” ì„¹ì…˜ìœ¼ë¡œ ì œê³µ)
        with st.expander("Show Debug Info", expanded=False):
            st.write("Detected Variables:", extract_variables(st.session_state.template_user_prompt))
            st.write("Current Prompt ID:", st.session_state.current_prompt_id)
            st.write("Current Version:", st.session_state.current_version)
            st.write("Number of Versions:", len(st.session_state.versions))
            st.write("Model:", st.session_state.model_name)
            st.write("Temperature:", st.session_state.temperature)
            st.write("Max Tokens:", st.session_state.max_tokens)
            st.write("Selected Provider:", st.session_state.selected_provider)

# ë©”ì¸ ì˜ì—­ì—ëŠ” í”„ë¡¬í”„íŠ¸ ì…ë ¥ê³¼ ì‘ë‹µ í‘œì‹œ ì˜ì—­ì„ ë°°ì¹˜
# ì™¼ìª½ ì—´ì—ëŠ” í”„ë¡¬í”„íŠ¸ ì…ë ¥, ì˜¤ë¥¸ìª½ ì—´ì—ëŠ” ì‘ë‹µ í‘œì‹œ
left_col, right_col = st.columns([1, 1])

# ì™¼ìª½ ì—´: í”„ë¡¬í”„íŠ¸ ì…ë ¥ ì˜ì—­ì„ ì„¸ë¡œë¡œ ë°°ì¹˜
with left_col:
    # ì„¸ë¡œ ë¶„í• ì„ ìœ„í•œ ì»¨í…Œì´ë„ˆ ì‚¬ìš©
    system_container = st.container()
    user_container = st.container()
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìƒë‹¨)
    with system_container:
        # st.subheader("System Prompt")
        st.markdown("#### System Prompt")
        system_prompt = st.text_area("Set a system instruction", value=st.session_state.system_prompt, height=100, key="system_prompt_area")
        st.session_state.system_prompt = system_prompt
    
    # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ (í•˜ë‹¨)
    with user_container:
        # st.subheader("User")
        st.markdown("#### User")
        template_user_prompt = st.text_area("Enter user message: ë³€ìˆ˜ëŠ” {variable} ë˜ëŠ” {{variable}} í˜•ì‹ìœ¼ë¡œ ì‚¬ìš©", 
                                          value=st.session_state.template_user_prompt or st.session_state.user_prompt, 
                                          height=250, 
                                          key="user_prompt_area")
        
        # í…œí”Œë¦¿ ì—…ë°ì´íŠ¸
        st.session_state.template_user_prompt = template_user_prompt
        
        # ë³€ìˆ˜ í† ê¸€ ë²„íŠ¼
        if st.button(("ğŸ·ï¸ Hide" if st.session_state.show_variables else "ğŸ·ï¸ Show") + " :orange[**Variables**]", key="variables_toggle_main"):
            st.session_state.show_variables = not st.session_state.show_variables
            
        # Run ë²„íŠ¼ ì¶”ê°€ (Show Variables ì•„ë˜ì— ë°°ì¹˜)
        if st.button("â–¶ï¸ :blue[**Run**]", key="run_button"):
            # ë³€ê²½ ì‚¬í•­ ìˆìœ¼ë©´ ë²„ì „ ì €ì¥
            is_new_version = save_version(st.session_state.system_prompt, st.session_state.user_prompt, st.session_state.template_user_prompt)
            if is_new_version:
                st.success(f"ìƒˆ ë²„ì „ {len(st.session_state.versions)} ìƒì„±ë¨")
                
            # ì‘ë‹µ íƒ­ìœ¼ë¡œ ì „í™˜í•˜ë„ë¡ ì•ˆë‚´
            st.success("ì‘ë‹µì´ 'Response' íƒ­ì— í‘œì‹œë©ë‹ˆë‹¤")
                
            # ì‘ë‹µ ìƒì„± (ë©”ì¸ ì˜ì—­ì˜ ì‘ë‹µ í”Œë ˆì´ìŠ¤í™€ë”ì— í‘œì‹œë¨)
            with st.spinner("Generating response..."):
                generate_response(
                    st.session_state.system_prompt,
                    st.session_state.user_prompt,
                    st.session_state.model_name,
                    st.session_state.temperature,
                    st.session_state.max_tokens
                )

        # í…œí”Œë¦¿ì—ì„œ ë³€ìˆ˜ ì¶”ì¶œ
        variables = extract_variables(template_user_prompt)
        
        # ë³€ìˆ˜ ì„¹ì…˜ í‘œì‹œ (í† ê¸€ ì‹œ)
        if st.session_state.show_variables:
            if variables:
                # ë³€ìˆ˜ ì…ë ¥ì„ ìœ„í•œ ì»¬ëŸ¼ ìƒì„± (í–‰ë‹¹ 2ê°œ ë³€ìˆ˜)
                cols_per_row = 2
                rows = (len(variables) + cols_per_row - 1) // cols_per_row
                
                for row in range(rows):
                    cols = st.columns(cols_per_row)
                    for col_idx in range(cols_per_row):
                        var_idx = row * cols_per_row + col_idx
                        if var_idx < len(variables):
                            var_name = variables[var_idx]
                            # ê¸°ì¡´ ê°’ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ë¹ˆ ë¬¸ìì—´
                            current_value = st.session_state.variables.get(var_name, "")
                            # ì´ ë³€ìˆ˜ì˜ ì…ë ¥ í•„ë“œ ìƒì„±
                            var_value = cols[col_idx].text_input(f"{var_name}", value=current_value, key=f"var_{var_name}")
                            # ë³€ìˆ˜ ê°’ ì €ì¥
                            st.session_state.variables[var_name] = var_value
            else:
                st.info("í…œí”Œë¦¿ì—ì„œ ë³€ìˆ˜ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. {variable} ë˜ëŠ” {{variable}} êµ¬ë¬¸ì„ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        
        # ë³€ìˆ˜ë¥¼ í…œí”Œë¦¿ì— ì ìš© (ê²°ê³¼ í”„ë¡¬í”„íŠ¸ëŠ” í‘œì‹œí•˜ì§€ ì•Šê³  ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì²˜ë¦¬)
        if variables:
            user_prompt = apply_variables(template_user_prompt, st.session_state.variables)
            # ë³€ìˆ˜ê°€ ì ìš©ëœ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸
            st.session_state.user_prompt = user_prompt
        else:
            # ë³€ìˆ˜ê°€ ì—†ìœ¼ë©´ í…œí”Œë¦¿ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            st.session_state.user_prompt = template_user_prompt

# ì „ì—­ ë³€ìˆ˜ë¡œ ì‘ë‹µ í”Œë ˆì´ìŠ¤í™€ë” ì„ ì–¸
response_placeholder = None



# ì˜¤ë¥¸ìª½ ì—´: ì‘ë‹µ í‘œì‹œì™€ ë²„ì „ íˆìŠ¤í† ë¦¬
with right_col:
    # íƒ­ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µê³¼ ë²„ì „ íˆìŠ¤í† ë¦¬ë¥¼ êµ¬ë¶„
    response_tab, history_tab = st.tabs(["**Response**", "**Version History**"])
    
    # ì‘ë‹µ íƒ­
    with response_tab:
        # ì‘ë‹µ í‘œì‹œë¥¼ ìœ„í•œ í”Œë ˆì´ìŠ¤í™€ë”
        response_placeholder = st.empty()
        
        # ì €ì¥ëœ ì‘ë‹µ í‘œì‹œ
        if st.session_state.response:
            response_placeholder.markdown(st.session_state.response)
    
    # ë²„ì „ íˆìŠ¤í† ë¦¬ íƒ­
    with history_tab:
        st.subheader("Version History")
        if st.session_state.versions:
            # ë²„ì „ íˆìŠ¤í† ë¦¬ë¥¼ ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•œ ì»¨í…Œì´ë„ˆì— ë°°ì¹˜
            with st.container():
                # ë²„ì „ ì •ë³´ë¥¼ í…Œì´ë¸”ë¡œ í‘œì‹œ
                version_data = []
                for i, version in enumerate(st.session_state.versions):
                    is_current = i + 1 == st.session_state.current_version
                    version_data.append({
                        "Version": version['version'],
                        "Timestamp": version['timestamp'],
                        "Current": "âœ“" if is_current else "",
                        "Action": f"version_{i}"  # ë²„íŠ¼ì„ ìœ„í•œ í‚¤
                    })
                
                # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë²„ì „ ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
                import pandas as pd
                df = pd.DataFrame(version_data)
                
                # í…Œì´ë¸” í‘œì‹œ
                st.dataframe(df[["Version", "Timestamp", "Current"]], hide_index=True)
                
                # ë²„ì „ ì„ íƒì„ ìœ„í•œ ë‘ ê°œì˜ ì»¬ëŸ¼ ìƒì„± (ì„ íƒ ë“œë¡­ë‹¤ìš´ê³¼ ë¡œë“œ ë²„íŠ¼)
                col1, col2 = st.columns([3, 1])
                with col1:
                    version_options = [f"Version {v['version']} ({v['timestamp']})" for v in st.session_state.versions]
                    selected_version_idx = st.selectbox(
                        "Select Version to Load",
                        options=range(len(version_options)),
                        format_func=lambda x: version_options[x],
                        index=st.session_state.current_version - 1 if st.session_state.current_version > 0 else 0
                    )
                with col2:
                    st.write("")  # ë²„íŠ¼ ì •ë ¬ì„ ìœ„í•œ ê³µë°±
                    st.write("")
                    if st.button("Load Version"):
                        if load_version(selected_version_idx):
                            st.success(f"ë²„ì „ {selected_version_idx + 1} ë¡œë“œ ì™„ë£Œ")
                
                # ë²„ì „ ë¹„êµ ê¸°ëŠ¥ (ì„ íƒì )
                with st.expander("Version Details", expanded=False):
                    if st.session_state.versions:
                        selected_version = st.session_state.versions[selected_version_idx]
                        st.write(f"**Version {selected_version['version']} Details:**")
                        st.write(f"Created: {selected_version['timestamp']}")
                        st.text_area("System Prompt", value=selected_version["system_prompt"], height=150, disabled=True)
                        st.text_area("User Prompt", value=selected_version["user_prompt"], height=150, disabled=True)
        else:
            st.info("ì•„ì§ ë²„ì „ íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ë³€ê²½ ì‚¬í•­ì´ ìˆìœ¼ë©´ 'Run' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ìƒˆ ë²„ì „ì„ ë§Œë“œì„¸ìš”.")


